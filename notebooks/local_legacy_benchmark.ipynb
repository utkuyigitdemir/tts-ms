{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy XTTS v2 - Local Benchmark\n",
    "\n",
    "Bu notebook Legacy XTTS v2 engine'ini lokal makinede test eder.\n",
    "\n",
    "**Engine:** Legacy XTTS v2 (Coqui TTS)\n",
    "**GPU:** Önerilir (NVIDIA CUDA)\n",
    "**Türkçe Desteği:** Evet (native multilingual)\n",
    "\n",
    "**NOT:** Coqui TTS Python 3.12+ ile uyumlu değildir. Bu notebook Miniconda ile Python 3.11 ortamı oluşturarak çalışır.\n",
    "\n",
    "Her soru için hem SORU hem CEVAP seslendiriliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Check Conda & Create Environment\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ENV_NAME = \"tts_py311\"\n",
    "\n",
    "# Check if conda is available\n",
    "try:\n",
    "    result = subprocess.run([\"conda\", \"--version\"], capture_output=True, text=True)\n",
    "    print(f\"Conda found: {result.stdout.strip()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Conda not found!\")\n",
    "    print(\"Please install Miniconda or Anaconda first:\")\n",
    "    print(\"  https://docs.conda.io/en/latest/miniconda.html\")\n",
    "    raise SystemExit(\"Conda required\")\n",
    "\n",
    "# Check if environment exists\n",
    "result = subprocess.run([\"conda\", \"env\", \"list\"], capture_output=True, text=True)\n",
    "env_exists = ENV_NAME in result.stdout\n",
    "\n",
    "if env_exists:\n",
    "    print(f\"Environment '{ENV_NAME}' already exists.\")\n",
    "else:\n",
    "    print(f\"Creating environment '{ENV_NAME}' with Python 3.11...\")\n",
    "    subprocess.run([\"conda\", \"create\", \"-n\", ENV_NAME, \"python=3.11\", \"-c\", \"conda-forge\", \"-y\"], check=True)\n",
    "    print(\"Environment created!\")\n",
    "\n",
    "# Show environments\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Install Dependencies\nimport subprocess\nimport sys\nimport os\n\nENV_NAME = \"tts_py311\"\nTTS_MS_PATH = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n\ndef run_in_env(cmd):\n    \"\"\"Run command in conda environment\"\"\"\n    full_cmd = [\"conda\", \"run\", \"-n\", ENV_NAME] + cmd\n    result = subprocess.run(full_cmd, capture_output=True, text=True)\n    if result.stdout:\n        print(result.stdout)\n    if result.stderr:\n        print(result.stderr)\n    return result.returncode\n\n# Install PyTorch with CUDA\nprint(\"Installing PyTorch...\")\nrun_in_env([\"pip\", \"install\", \"-q\", \"torch\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n\n# Install Coqui TTS (use coqui-tts package, not TTS)\nprint(\"\\nInstalling Coqui TTS...\")\nrun_in_env([\"pip\", \"install\", \"-q\", \"coqui-tts\"])\n\n# Install tts-ms from local path\nprint(f\"\\nInstalling tts-ms from {TTS_MS_PATH}...\")\nrun_in_env([\"pip\", \"install\", \"-q\", TTS_MS_PATH])\n\n# Verify\nprint(\"\\n\" + \"=\"*60)\nprint(\"VERIFICATION:\")\nrun_in_env([\"python\", \"--version\"])\nrun_in_env([\"python\", \"-c\", \"import torch; print('PyTorch:', torch.__version__, 'CUDA:', torch.cuda.is_available())\"])\nrun_in_env([\"python\", \"-c\", \"from TTS.api import TTS; print('Coqui TTS: OK')\"])\nrun_in_env([\"python\", \"-c\", \"import tts_ms; print('tts-ms: OK')\"])\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Setup Output Directories & Create Benchmark Script\nimport os\nimport shutil\n\nENGINE_NAME = \"legacy\"\nMODEL_NAME = \"xtts_v2\"\n\n# Use local output directory\nNOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\nBASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\", ENGINE_NAME)\nAUDIO_DIR = os.path.join(BASE_DIR, \"audio\")\nMODEL_DIR = os.path.join(NOTEBOOK_DIR, \"cache\", \"xtts\")\n\n# Clean start\nif os.path.exists(BASE_DIR):\n    shutil.rmtree(BASE_DIR)\nos.makedirs(AUDIO_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\n\nprint(f\"Output directory: {BASE_DIR}\")\nprint(f\"Model cache: {MODEL_DIR}\")\n\n# Write the benchmark script\nSCRIPT = f'''\nimport os\nimport sys\nimport json\nimport time\nimport psutil\nfrom datetime import datetime\n\n# Fix matplotlib backend issue\nos.environ[\"MPLBACKEND\"] = \"agg\"\n\n# Environment setup\nos.environ[\"TTS_MODEL_TYPE\"] = \"legacy\"\nos.environ[\"TTS_MS_LOG_LEVEL\"] = \"4\"\nos.environ[\"TTS_MS_RESOURCES_ENABLED\"] = \"1\"\nos.environ[\"COQUI_TOS_AGREED\"] = \"1\"\nos.environ[\"TTS_HOME\"] = r\"{MODEL_DIR}\"\n\nENGINE_NAME = \"{ENGINE_NAME}\"\nMODEL_NAME = \"{MODEL_NAME}\"\nBASE_DIR = r\"{BASE_DIR}\"\nAUDIO_DIR = r\"{AUDIO_DIR}\"\n\nfrom tts_ms.services import TTSService\nfrom tts_ms.services.tts_service import SynthesizeRequest\nfrom tts_ms.core.config import Settings\n\nprocess = psutil.Process()\nCPU_COUNT = psutil.cpu_count()\nresource_logs = []\nresults = []\n\ndef get_resources():\n    return {{\"cpu\": process.cpu_percent(), \"ram_mb\": process.memory_info().rss / 1024 / 1024}}\n\nQUESTIONS = [\n    {{\"id\": \"01\", \"question\": \"Sizi neden işe almalıyız?\",\n     \"answer\": \"Güçlü analitik düşünme becerilerim ve takım çalışmasına yatkınlığım sayesinde projelere değer katabilirim. Ayrıca sürekli öğrenmeye açık yapım ve problem çözme yeteneklerim, şirketinizin hedeflerine ulaşmasında önemli katkılar sağlayacaktır.\"}},\n    {{\"id\": \"02\", \"question\": \"Siz bizi neden seçtiniz?\",\n     \"answer\": \"Şirketinizin yenilikçi yaklaşımı ve sektördeki lider konumu beni çok etkiledi. Kariyer hedeflerimle örtüşen bu ortamda kendimi geliştirebileceğime ve anlamlı projeler üzerinde çalışabileceğime inanıyorum.\"}},\n    {{\"id\": \"03\", \"question\": \"Kötü özellikleriniz nelerdir?\",\n     \"answer\": \"Bazen aşırı detaycı olabiliyorum, bu da zaman yönetimimi olumsuz etkileyebiliyor. Ancak bu özelliğimin farkındayım ve önceliklendirme teknikleri kullanarak bu durumu yönetmeye çalışıyorum.\"}},\n    {{\"id\": \"04\", \"question\": \"Beş yıl sonra kendinizi nerede görüyorsunuz?\",\n     \"answer\": \"Beş yıl içinde teknik liderlik pozisyonunda olmayı hedefliyorum. Ekip yönetimi deneyimi kazanarak şirketin büyümesine stratejik katkılar sağlamak istiyorum.\"}},\n    {{\"id\": \"05\", \"question\": \"Maaş beklentiniz nedir?\",\n     \"answer\": \"Piyasa koşullarını ve pozisyonun gerekliliklerini değerlendirerek, deneyimime ve yeteneklerime uygun rekabetçi bir maaş beklentim var. Bu konuda esnek olmaya ve karşılıklı bir anlaşmaya varmaya açığım.\"}}\n]\n\nprint(\"=\"*60)\nprint(\"INITIALIZING TTS SERVICE\")\nprint(\"=\"*60)\n\nres_before = get_resources()\nstart = time.time()\n\nsettings = Settings(raw={{\n    \"tts\": {{\n        \"engine\": \"legacy\",\n        \"model_name\": \"tts_models/multilingual/multi-dataset/xtts_v2\",\n        \"device\": \"cuda\",\n        \"default_language\": \"tr\",\n        \"default_speaker\": \"Ana Florence\"\n    }},\n    \"cache\": {{\"enabled\": False}},\n    \"storage\": {{\"enabled\": False}},\n    \"logging\": {{\"level\": 4}}\n}})\nservice = TTSService(settings)\ninit_time = time.time() - start\nres_after = get_resources()\nresource_logs.append({{\"stage\": \"init\", \"duration\": init_time, \"cpu\": res_after[\"cpu\"], \"ram_delta\": res_after[\"ram_mb\"] - res_before[\"ram_mb\"]}})\nprint(f\"Initialized in {{init_time:.2f}}s\")\n\n# Warmup\nprint(\"\\\\nWarmup...\")\nres_before = get_resources()\nstart = time.time()\n_ = service.synthesize(SynthesizeRequest(text=\"Merhaba.\"), request_id=\"warmup\")\nwarmup_time = time.time() - start\nres_after = get_resources()\nresource_logs.append({{\"stage\": \"warmup\", \"duration\": warmup_time, \"cpu\": res_after[\"cpu\"], \"ram_delta\": res_after[\"ram_mb\"] - res_before[\"ram_mb\"]}})\nprint(f\"Warmup done in {{warmup_time:.2f}}s\")\n\nprint(\"\\\\n\" + \"=\"*60)\nprint(f\"SYNTHESIZING {{len(QUESTIONS)}} QUESTIONS + ANSWERS\")\nprint(\"=\"*60)\n\nfor q in QUESTIONS:\n    print(f\"\\\\n[{{q['id']}}] {{q['question']}}\")\n    \n    for typ, text in [(\"soru\", q[\"question\"]), (\"cevap\", q[\"answer\"])]:\n        print(f\"  {{typ.upper()}}: \", end=\"\", flush=True)\n        res_before = get_resources()\n        start = time.time()\n        try:\n            result = service.synthesize(SynthesizeRequest(text=text), request_id=f\"{{q['id']}}_{{typ}}\")\n            elapsed = time.time() - start\n            res_after = get_resources()\n            \n            path = os.path.join(AUDIO_DIR, f\"{{q['id']}}_{{typ}}.wav\")\n            with open(path, \"wb\") as f:\n                f.write(result.wav_bytes)\n            \n            cpu_norm = res_after[\"cpu\"] / CPU_COUNT\n            ram_delta = res_after[\"ram_mb\"] - res_before[\"ram_mb\"]\n            \n            resource_logs.append({{\"stage\": f\"{{q['id']}}_{{typ}}\", \"duration\": elapsed, \"cpu\": res_after[\"cpu\"], \"cpu_norm\": cpu_norm, \"ram_delta\": ram_delta, \"size_kb\": len(result.wav_bytes)/1024}})\n            results.append({{\"id\": q[\"id\"], \"type\": typ, \"time\": elapsed, \"size\": len(result.wav_bytes), \"cpu\": cpu_norm, \"ram_delta\": ram_delta, \"status\": \"OK\"}})\n            \n            print(f\"{{elapsed:.2f}}s | {{len(result.wav_bytes)/1024:.1f}} KB | CPU:{{cpu_norm:.0f}}% | OK\")\n        except Exception as e:\n            results.append({{\"id\": q[\"id\"], \"type\": typ, \"time\": time.time()-start, \"size\": 0, \"cpu\": 0, \"ram_delta\": 0, \"status\": f\"FAIL: {{e}}\"}})\n            print(f\"FAIL: {{e}}\")\n\nsuccessful = [r for r in results if r[\"status\"] == \"OK\"]\nprint(f\"\\\\n\" + \"=\"*60)\nprint(f\"COMPLETE: {{len(successful)}}/{{len(results)}} successful\")\nprint(\"=\"*60)\n\n# Save results\noutput_data = {{\n    \"engine\": ENGINE_NAME,\n    \"model\": MODEL_NAME,\n    \"init_time\": init_time,\n    \"warmup_time\": warmup_time,\n    \"results\": results,\n    \"resource_logs\": resource_logs,\n    \"timestamp\": datetime.now().isoformat()\n}}\n\nwith open(os.path.join(BASE_DIR, \"results.json\"), \"w\", encoding=\"utf-8\") as f:\n    json.dump(output_data, f, indent=2, ensure_ascii=False)\n\nprint(f\"\\\\nResults saved to {{BASE_DIR}}\")\n'''\n\nscript_path = os.path.join(NOTEBOOK_DIR, \"benchmark_script.py\")\nwith open(script_path, \"w\", encoding=\"utf-8\") as f:\n    f.write(SCRIPT)\n\nprint(f\"Benchmark script created: {script_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: Run Benchmark\nimport subprocess\nimport os\n\nENV_NAME = \"tts_py311\"\nNOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\nSCRIPT_PATH = os.path.join(NOTEBOOK_DIR, \"benchmark_script.py\")\n\nprint(\"Running benchmark in Python 3.11 environment...\")\nprint(\"This may take a while on first run (model download ~1.8GB)\\n\")\n\n# Set MPLBACKEND environment variable and run\nenv = os.environ.copy()\nenv[\"MPLBACKEND\"] = \"agg\"\n\nresult = subprocess.run(\n    [\"conda\", \"run\", \"-n\", ENV_NAME, \"python\", SCRIPT_PATH],\n    env=env,\n    capture_output=False\n)\n\nif result.returncode != 0:\n    print(f\"Benchmark failed with return code {result.returncode}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Play Audio Files\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ENGINE_NAME = \"legacy\"\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "AUDIO_DIR = os.path.join(NOTEBOOK_DIR, \"output\", ENGINE_NAME, \"audio\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AUDIO PLAYBACK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "audio_files = sorted(Path(AUDIO_DIR).glob(\"*.wav\"))\n",
    "\n",
    "if not audio_files:\n",
    "    print(\"No audio files found!\")\n",
    "else:\n",
    "    for wav in audio_files:\n",
    "        print(f\"\\n{wav.name}:\")\n",
    "        display(Audio(str(wav)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Generate Reports\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "\n",
    "ENGINE_NAME = \"legacy\"\n",
    "MODEL_NAME = \"xtts_v2\"\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\", ENGINE_NAME)\n",
    "CPU_COUNT = psutil.cpu_count()\n",
    "\n",
    "# Load results\n",
    "with open(os.path.join(BASE_DIR, \"results.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "results = data[\"results\"]\n",
    "resource_logs = data[\"resource_logs\"]\n",
    "init_time = data[\"init_time\"]\n",
    "warmup_time = data[\"warmup_time\"]\n",
    "\n",
    "successful = [r for r in results if r[\"status\"] == \"OK\"]\n",
    "soru_results = [r for r in successful if r[\"type\"] == \"soru\"]\n",
    "cevap_results = [r for r in successful if r[\"type\"] == \"cevap\"]\n",
    "\n",
    "total_size_kb = sum(r[\"size\"] for r in successful) / 1024\n",
    "avg_soru = sum(r[\"time\"] for r in soru_results) / len(soru_results) if soru_results else 0\n",
    "avg_cevap = sum(r[\"time\"] for r in cevap_results) / len(cevap_results) if cevap_results else 0\n",
    "\n",
    "synth_logs = [r for r in resource_logs if r[\"stage\"] not in [\"init\", \"warmup\"]]\n",
    "avg_cpu = sum(r.get(\"cpu_norm\", 0) for r in synth_logs) / len(synth_logs) if synth_logs else 0\n",
    "max_cpu = max(r.get(\"cpu_norm\", 0) for r in synth_logs) if synth_logs else 0\n",
    "total_ram = sum(r.get(\"ram_delta\", 0) for r in synth_logs)\n",
    "\n",
    "# summary.txt\n",
    "summary = f\"\"\"============================================================\n",
    "TTS-MS BENCHMARK - LEGACY XTTS v2 (LOCAL)\n",
    "============================================================\n",
    "Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Platform: Local (Miniconda Python 3.11)\n",
    "Model: {MODEL_NAME}\n",
    "\n",
    "PERFORMANS:\n",
    "- Init: {init_time:.2f}s\n",
    "- Warmup: {warmup_time:.2f}s\n",
    "\n",
    "SONUCLAR:\n",
    "- Toplam: 5 soru\n",
    "- Soru Audio: {len(soru_results)}/5 basarili (ort: {avg_soru:.2f}s)\n",
    "- Cevap Audio: {len(cevap_results)}/5 basarili (ort: {avg_cevap:.2f}s)\n",
    "- Toplam Audio: {total_size_kb:.1f} KB\n",
    "\n",
    "KAYNAK KULLANIMI:\n",
    "- Ortalama CPU: {avg_cpu:.0f}%\n",
    "- Maksimum CPU: {max_cpu:.0f}%\n",
    "- RAM Delta: {total_ram:+.1f} MB\n",
    "\n",
    "DETAYLAR:\n",
    "\"\"\"\n",
    "for r in results:\n",
    "    s = \"OK\" if r[\"status\"] == \"OK\" else \"FAIL\"\n",
    "    summary += f\"[{r['id']}_{r['type']}] {r['time']:.2f}s | {r['size']/1024:.1f} KB | CPU:{r['cpu']:.0f}% | {s}\\n\"\n",
    "summary += f\"\\nAudio: {os.path.join(BASE_DIR, 'audio')}\\n============================================================\\n\"\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create ZIP (Optional)\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ENGINE_NAME = \"legacy\"\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\", ENGINE_NAME)\n",
    "AUDIO_DIR = os.path.join(BASE_DIR, \"audio\")\n",
    "\n",
    "zip_path = os.path.join(BASE_DIR, \"legacy_benchmark.zip\")\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.write(os.path.join(BASE_DIR, \"summary.txt\"), \"summary.txt\")\n",
    "    zf.write(os.path.join(BASE_DIR, \"results.json\"), \"results.json\")\n",
    "    for wav in Path(AUDIO_DIR).glob(\"*.wav\"):\n",
    "        zf.write(wav, f\"audio/{wav.name}\")\n",
    "\n",
    "print(f\"ZIP created: {zip_path}\")\n",
    "print(f\"Size: {Path(zip_path).stat().st_size/1024:.1f} KB\")\n",
    "print(\"\\nContents:\")\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "    for f in zf.namelist():\n",
    "        print(f\"  {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}