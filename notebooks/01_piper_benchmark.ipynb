{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Piper TTS Benchmark\n",
        "\n",
        "Bu notebook Piper TTS engine'ini 5 Türkçe mülakat sorusu ile test eder.\n",
        "\n",
        "**Engine:** Piper (CPU-only)\n",
        "**GPU:** Gerekmez\n",
        "**Türkçe Desteği:** Evet (tr_TR-dfki-medium model)\n",
        "\n",
        "Her soru için hem SORU hem CEVAP seslendiriliyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Drive mounted successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Install Dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "\n",
        "!pip install piper-tts\n",
        "\n",
        "import os\n",
        "TTS_MS_PATH = \"/content/drive/MyDrive/tts-ms\"\n",
        "if not os.path.exists(TTS_MS_PATH):\n",
        "    raise FileNotFoundError(f\"tts-ms not found at {TTS_MS_PATH}\")\n",
        "\n",
        "!pip install \"/content/drive/MyDrive/tts-ms\"\n",
        "\n",
        "import tts_ms\n",
        "print(f\"tts_ms installed: {tts_ms.__file__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Setup & Download Model\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "ENGINE_NAME = \"piper\"\n",
        "MODEL_NAME = \"tr_TR-dfki-medium\"\n",
        "\n",
        "BASE_DIR = f\"/content/drive/MyDrive/tts-ms/output/{ENGINE_NAME}\"\n",
        "AUDIO_DIR = f\"{BASE_DIR}/audio\"\n",
        "\n",
        "# Temiz baslangic\n",
        "import shutil\n",
        "if os.path.exists(BASE_DIR):\n",
        "    shutil.rmtree(BASE_DIR)\n",
        "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Output: {BASE_DIR}\")\n",
        "\n",
        "os.environ[\"TTS_MODEL_TYPE\"] = ENGINE_NAME\n",
        "os.environ[\"TTS_MS_LOG_LEVEL\"] = \"4\"\n",
        "os.environ[\"TTS_MS_RESOURCES_ENABLED\"] = \"1\"\n",
        "\n",
        "# Model indir\n",
        "MODEL_DIR = \"/content/drive/MyDrive/tts-ms/cache/piper\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "MODEL_PATH = f\"{MODEL_DIR}/{MODEL_NAME}.onnx\"\n",
        "CONFIG_PATH = f\"{MODEL_DIR}/{MODEL_NAME}.onnx.json\"\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"Downloading {MODEL_NAME}...\")\n",
        "    !wget -q -O \"{MODEL_PATH}\" \"https://huggingface.co/rhasspy/piper-voices/resolve/main/tr/tr_TR/dfki/medium/tr_TR-dfki-medium.onnx\"\n",
        "    !wget -q -O \"{CONFIG_PATH}\" \"https://huggingface.co/rhasspy/piper-voices/resolve/main/tr/tr_TR/dfki/medium/tr_TR-dfki-medium.onnx.json\"\n",
        "    print(\"Model downloaded.\")\n",
        "else:\n",
        "    print(f\"Model cached: {MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Initialize TTSService\n",
        "import time\n",
        "import psutil\n",
        "from tts_ms.services import TTSService\n",
        "from tts_ms.services.tts_service import SynthesizeRequest\n",
        "from tts_ms.core.config import Settings\n",
        "\n",
        "process = psutil.Process()\n",
        "CPU_COUNT = psutil.cpu_count()\n",
        "resource_logs = []\n",
        "\n",
        "def get_resources():\n",
        "    return {'cpu': process.cpu_percent(), 'ram_mb': process.memory_info().rss / 1024 / 1024}\n",
        "\n",
        "print(\"Initializing TTSService...\")\n",
        "res_before = get_resources()\n",
        "start = time.time()\n",
        "\n",
        "settings = Settings(raw={\n",
        "    'tts': {\n",
        "        'engine': 'piper',\n",
        "        'device': 'cpu',\n",
        "        'piper': {'model_path': MODEL_PATH, 'config_path': CONFIG_PATH}\n",
        "    },\n",
        "    'cache': {'enabled': False},\n",
        "    'storage': {'enabled': False},\n",
        "    'logging': {'level': 4}\n",
        "})\n",
        "service = TTSService(settings)\n",
        "init_time = time.time() - start\n",
        "res_after = get_resources()\n",
        "resource_logs.append({'stage': 'init', 'duration': init_time, 'cpu': res_after['cpu'], 'ram_delta': res_after['ram_mb'] - res_before['ram_mb']})\n",
        "print(f\"Initialized in {init_time:.2f}s\")\n",
        "\n",
        "# Warmup\n",
        "print(\"\\nWarmup...\")\n",
        "res_before = get_resources()\n",
        "start = time.time()\n",
        "_ = service.synthesize(SynthesizeRequest(text=\"Merhaba.\"), request_id=\"warmup\")\n",
        "warmup_time = time.time() - start\n",
        "res_after = get_resources()\n",
        "resource_logs.append({'stage': 'warmup', 'duration': warmup_time, 'cpu': res_after['cpu'], 'ram_delta': res_after['ram_mb'] - res_before['ram_mb']})\n",
        "print(f\"Warmup done in {warmup_time:.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Synthesize\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "QUESTIONS = [\n",
        "    {\"id\": \"01\", \"question\": \"Sizi neden işe almalıyız?\",\n",
        "     \"answer\": \"Güçlü analitik düşünme becerilerim ve takım çalışmasına yatkınlığım sayesinde projelere değer katabilirim. Ayrıca sürekli öğrenmeye açık yapım ve problem çözme yeteneklerim, şirketinizin hedeflerine ulaşmasında önemli katkılar sağlayacaktır.\"},\n",
        "    {\"id\": \"02\", \"question\": \"Siz bizi neden seçtiniz?\",\n",
        "     \"answer\": \"Şirketinizin yenilikçi yaklaşımı ve sektördeki lider konumu beni çok etkiledi. Kariyer hedeflerimle örtüşen bu ortamda kendimi geliştirebileceğime ve anlamlı projeler üzerinde çalışabileceğime inanıyorum.\"},\n",
        "    {\"id\": \"03\", \"question\": \"Kötü özellikleriniz nelerdir?\",\n",
        "     \"answer\": \"Bazen aşırı detaycı olabiliyorum, bu da zaman yönetimimi olumsuz etkileyebiliyor. Ancak bu özelliğimin farkındayım ve önceliklendirme teknikleri kullanarak bu durumu yönetmeye çalışıyorum.\"},\n",
        "    {\"id\": \"04\", \"question\": \"Beş yıl sonra kendinizi nerede görüyorsunuz?\",\n",
        "     \"answer\": \"Beş yıl içinde teknik liderlik pozisyonunda olmayı hedefliyorum. Ekip yönetimi deneyimi kazanarak şirketin büyümesine stratejik katkılar sağlamak istiyorum.\"},\n",
        "    {\"id\": \"05\", \"question\": \"Maaş beklentiniz nedir?\",\n",
        "     \"answer\": \"Piyasa koşullarını ve pozisyonun gerekliliklerini değerlendirerek, deneyimime ve yeteneklerime uygun rekabetçi bir maaş beklentim var. Bu konuda esnek olmaya ve karşılıklı bir anlaşmaya varmaya açığım.\"}\n",
        "]\n",
        "\n",
        "results = []\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"SYNTHESIZING {len(QUESTIONS)} QUESTIONS + ANSWERS\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "for q in QUESTIONS:\n",
        "    print(f\"\\n[{q['id']}] {q['question']}\")\n",
        "    \n",
        "    for typ, text in [('soru', q['question']), ('cevap', q['answer'])]:\n",
        "        print(f\"  {typ.upper()}: \", end=\"\", flush=True)\n",
        "        res_before = get_resources()\n",
        "        start = time.time()\n",
        "        try:\n",
        "            result = service.synthesize(SynthesizeRequest(text=text), request_id=f\"{q['id']}_{typ}\")\n",
        "            elapsed = time.time() - start\n",
        "            res_after = get_resources()\n",
        "            \n",
        "            path = f\"{AUDIO_DIR}/{q['id']}_{typ}.wav\"\n",
        "            with open(path, 'wb') as f:\n",
        "                f.write(result.wav_bytes)\n",
        "            \n",
        "            cpu_norm = res_after['cpu'] / CPU_COUNT\n",
        "            ram_delta = res_after['ram_mb'] - res_before['ram_mb']\n",
        "            \n",
        "            resource_logs.append({'stage': f\"{q['id']}_{typ}\", 'duration': elapsed, 'cpu': res_after['cpu'], 'cpu_norm': cpu_norm, 'ram_delta': ram_delta, 'size_kb': len(result.wav_bytes)/1024})\n",
        "            results.append({'id': q['id'], 'type': typ, 'time': elapsed, 'size': len(result.wav_bytes), 'cpu': cpu_norm, 'ram_delta': ram_delta, 'status': 'OK'})\n",
        "            \n",
        "            print(f\"{elapsed:.2f}s | {len(result.wav_bytes)/1024:.1f} KB | CPU:{cpu_norm:.0f}% | OK\")\n",
        "            display(Audio(path))\n",
        "        except Exception as e:\n",
        "            results.append({'id': q['id'], 'type': typ, 'time': time.time()-start, 'size': 0, 'cpu': 0, 'ram_delta': 0, 'status': f'FAIL: {e}'})\n",
        "            print(f\"FAIL: {e}\")\n",
        "\n",
        "successful = [r for r in results if r['status'] == 'OK']\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"COMPLETE: {len(successful)}/{len(results)} successful\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Generate Reports\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "successful = [r for r in results if r['status'] == 'OK']\n",
        "soru_results = [r for r in successful if r['type'] == 'soru']\n",
        "cevap_results = [r for r in successful if r['type'] == 'cevap']\n",
        "\n",
        "total_size_kb = sum(r['size'] for r in successful) / 1024\n",
        "avg_soru = sum(r['time'] for r in soru_results) / len(soru_results) if soru_results else 0\n",
        "avg_cevap = sum(r['time'] for r in cevap_results) / len(cevap_results) if cevap_results else 0\n",
        "\n",
        "synth_logs = [r for r in resource_logs if r['stage'] not in ['init', 'warmup']]\n",
        "avg_cpu = sum(r.get('cpu_norm', 0) for r in synth_logs) / len(synth_logs) if synth_logs else 0\n",
        "max_cpu = max(r.get('cpu_norm', 0) for r in synth_logs) if synth_logs else 0\n",
        "total_ram = sum(r.get('ram_delta', 0) for r in synth_logs)\n",
        "\n",
        "# summary.txt\n",
        "summary = f\"\"\"============================================================\n",
        "TTS-MS BENCHMARK - PIPER\n",
        "============================================================\n",
        "Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "Platform: Google Colab (CPU - {CPU_COUNT} core)\n",
        "Model: {MODEL_NAME}\n",
        "\n",
        "PERFORMANS:\n",
        "- Init: {init_time:.2f}s\n",
        "- Warmup: {warmup_time:.2f}s\n",
        "\n",
        "SONUCLAR:\n",
        "- Toplam: {len(QUESTIONS)} soru\n",
        "- Soru Audio: {len(soru_results)}/5 basarili (ort: {avg_soru:.2f}s)\n",
        "- Cevap Audio: {len(cevap_results)}/5 basarili (ort: {avg_cevap:.2f}s)\n",
        "- Toplam Audio: {total_size_kb:.1f} KB\n",
        "\n",
        "KAYNAK KULLANIMI:\n",
        "- Ortalama CPU: {avg_cpu:.0f}%\n",
        "- Maksimum CPU: {max_cpu:.0f}%\n",
        "- RAM Delta: {total_ram:+.1f} MB\n",
        "- GPU: N/A (CPU-only model)\n",
        "\n",
        "DETAYLAR:\n",
        "\"\"\"\n",
        "for r in results:\n",
        "    s = 'OK' if r['status'] == 'OK' else 'FAIL'\n",
        "    summary += f\"[{r['id']}_{r['type']}] {r['time']:.2f}s | {r['size']/1024:.1f} KB | CPU:{r['cpu']:.0f}% | {s}\\n\"\n",
        "summary += f\"\\nAudio: {AUDIO_DIR}\\n============================================================\\n\"\n",
        "\n",
        "with open(f\"{BASE_DIR}/summary.txt\", 'w', encoding='utf-8') as f:\n",
        "    f.write(summary)\n",
        "\n",
        "# resource.log\n",
        "res_log = f\"\"\"============================================================\n",
        "TTS-MS PIPER - RESOURCE LOG\n",
        "============================================================\n",
        "Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "Platform: Google Colab (CPU - {CPU_COUNT} core)\n",
        "Model: {MODEL_NAME}\n",
        "\n",
        "KAYNAK KULLANIMI (ADIM ADIM):\n",
        "============================================================\\n\"\"\"\n",
        "for r in resource_logs:\n",
        "    if r['stage'] == 'init':\n",
        "        res_log += f\"[INIT] {r['duration']:.2f}s | RAM: {r['ram_delta']:+.1f} MB\\n\"\n",
        "    elif r['stage'] == 'warmup':\n",
        "        res_log += f\"[WARMUP] {r['duration']:.2f}s | CPU: {r['cpu']/CPU_COUNT:.0f}% | RAM: {r['ram_delta']:+.1f} MB\\n\"\n",
        "    else:\n",
        "        res_log += f\"[{r['stage'].upper()}] {r['duration']:.2f}s | {r.get('size_kb',0):.1f} KB | CPU: {r.get('cpu_norm',0):.0f}% | RAM: {r['ram_delta']:+.1f} MB\\n\"\n",
        "res_log += f\"\"\"\\n============================================================\n",
        "OZET:\n",
        "- Ortalama CPU: {avg_cpu:.0f}%\n",
        "- Maksimum CPU: {max_cpu:.0f}%\n",
        "- Toplam RAM Delta: {total_ram:+.1f} MB\n",
        "- Ortalama Synth: {(avg_soru+avg_cevap)/2:.2f}s\n",
        "============================================================\\n\"\"\"\n",
        "\n",
        "with open(f\"{BASE_DIR}/resource.log\", 'w', encoding='utf-8') as f:\n",
        "    f.write(res_log)\n",
        "\n",
        "# results.json\n",
        "with open(f\"{BASE_DIR}/results.json\", 'w', encoding='utf-8') as f:\n",
        "    json.dump({'engine': ENGINE_NAME, 'model': MODEL_NAME, 'results': results, 'resources': resource_logs,\n",
        "               'init_time': init_time, 'warmup_time': warmup_time, 'avg_cpu': avg_cpu, 'max_cpu': max_cpu}, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(summary)\n",
        "print(\"\\n\" + res_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Download ZIP\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = f\"{BASE_DIR}/piper_benchmark.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    zf.write(f\"{BASE_DIR}/summary.txt\", \"summary.txt\")\n",
        "    zf.write(f\"{BASE_DIR}/resource.log\", \"resource.log\")\n",
        "    zf.write(f\"{BASE_DIR}/results.json\", \"results.json\")\n",
        "    for wav in Path(AUDIO_DIR).glob(\"*.wav\"):\n",
        "        zf.write(wav, f\"audio/{wav.name}\")\n",
        "\n",
        "print(f\"ZIP: {zip_path}\")\n",
        "print(f\"Size: {Path(zip_path).stat().st_size/1024:.1f} KB\")\n",
        "print(\"\\nContents:\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    for f in zf.namelist():\n",
        "        print(f\"  {f}\")\n",
        "\n",
        "files.download(zip_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
